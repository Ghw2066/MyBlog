---
title: "Spark概述及运行架构"
date: 2019-10-29T17:04:28+11:00
draft: false
categories:
 - Spark
tags:
 - Spark
---

## Spark概述

- 运行速度快：使用DAG执行引擎以支持循环数据流与内存计算，比MapReduce迭代式计算高效。
- 易用：Scala, Java, Python, R并且支持使用Spark Shell进行交互式编程
- 通用性：SQL, 流式计算, ML，图算法组件
- 运行模式多样：
  1. 独立集群模式
  2. 可运行于Hadoop中，借助HDFS，YARN，Hbase，Hive等，同时得到了Hadoop安全性上的优势
  3. 可运行于Amazon EC2等云环境

Spark由Scala编写，Scala是多范式编程语言，具备强大的并发性，支持函数式编程，可以更好地支持分布式系统。Scala语法简洁，能提供优雅的API。最重要的是，Scala兼容Java，运行在JVM之上，运行速度快，且能融合到Hadoop生态圈中。

Scala提供REPL(Read-Eval-Print-Loop, 交互式解释器)，提高程序开发效率。

#### Spark与Hadoop对比

- Hadoop缺点：
  1. 表达能力有限，并不是所有任务都可以用MR完成
  2. 磁盘IO开销很大，要不断的读写磁盘，拖慢了速度
  3. 延迟高，map与reduce之间通过读写磁盘通信，任务之间衔接涉及IO开销
  4. 在前一个任务执行完成之前，其他任务就无法开始，难以胜任复杂、多阶段计算任务

- Spark相对Hadoop的优点
  1. Spark的计算模式也属于MapReduce，但不局限与Map和Reduce操作，还提供了多种数据集操作类型， 编程模型比Hadoop MapReduce更灵活，更为适合数据挖掘、机器学习的任务。
  2. Spark提供了内存计算，可将中间结果放到内存中，对于迭代运算效率更高
  3. Spark基于DAG的任务调度执行机制，相对于Hadoop，虽然有Tez框架也实现了DAG任务调度，但是仅是Tez框架，不是MapReduce框架本身，所以Spark要由于Hadoop MapReduce的迭代执行机制。

![Spark与Hadoop流程对比](/images/spark/spark1.png)

## Spark生态系统

- Spark设计：遵循 “一个软件栈满足不同应用场景” 的理念，逐渐形成了一套完整的生态系统

- Spark可以部署在资源管理器YARN之上，提供一站式的大数据解决方案
- Spark所提供的生态系统同时支持**批处理**、**交互式查询**和**流数据处理**
- Spark生态系统已经成为伯克利数据分析软件栈BDAS(Berkeley Data Analytics Stack)的重要组成部分
- 生态系统组成：
  1. Spark Core 提供内存计算
  2. Spark SQL 提供交互式查询分析
  3. Spark Streaming 提供流计算功能
  4. MLlib 提供机器学习算法库的组件
  5. GraphX 提供图计算

![Spark生态系统组件的应用场景](/images/spark/spark2.png)

## Spark 运行架构

![Spark基本概念](/images/spark/spark4.png)

**RDD**: Resillient Distributed Dataset (弹性分布式数据集)

**DAG**: Directed Acyclic Gragh(有向无环图)

**Executor**: 是运行在工作节点(worknode)的一个进程，负责运行Task

**Application**: 用户编写的Spark应用程序

**Task**: 运行在Executor上的工作单元

**Job**: 一个job包含多个RDD及作用于相应RDD上的各种操作

**Stage**: 是job的基本调度单位，一个job会分为多组Task，每组Task被称为Stage，或者也被称为TaskSet，代表了一组关联的、相互之间没有Shuffle依赖关系的任务组成的任务集

![Spark架构设计](/images/spark/spark3.png)

**Cluster Manager**: 集群资源管理器，是中间最核心的部分，负责对整个spark应用程序进行资源的分配和管理调度的，可以用spark自带的资源管理器，也可以用其他的开源框架，比如Mesos或YARN

**Worker Node**：运行作业任务的工作节点，其中Executor负责任务执行的具体进程

**Driver Program**：任务控制节点，类似管家，负责整个应用的任务控制的，应用提交后，生成有向无环图DAG，将DAG分成多个阶段，对多个阶段进行任务拆解，把任务分给相关的具体的Executor去执行

#### 相比Hadoop MapReduce, Spark的Executor优点

1. 利用多线程来执行具体的任务，减少任务的启动开销
2. Executor中有一个BlockManager存储模块，会将内存和磁盘共同作为存储设备，有效减少IO开销

#### 运行基本流程

SparkContext 

