---
title: "Spark概述及运行架构"
date: 2019-10-29T17:04:28+11:00
draft: false
categories:
 - Spark
tags:
 - Spark
---

## Spark概述

- 运行速度快：使用DAG执行引擎以支持循环数据流与内存计算，比MapReduce迭代式计算高效。
- 易用：Scala, Java, Python, R并且支持使用Spark Shell进行交互式编程
- 通用性：SQL, 流式计算, ML，图算法组件
- 运行模式多样：
  1. 独立集群模式
  2. 可运行于Hadoop中，借助HDFS，YARN，Hbase，Hive等，同时得到了Hadoop安全性上的优势
  3. 可运行于Amazon EC2等云环境

Spark由Scala编写，Scala是多范式编程语言，具备强大的并发性，支持函数式编程，可以更好地支持分布式系统。Scala语法简洁，能提供优雅的API。最重要的是，Scala兼容Java，运行在JVM之上，运行速度快，且能融合到Hadoop生态圈中。

Scala提供REPL(Read-Eval-Print-Loop, 交互式解释器)，提高程序开发效率。

#### Spark与Hadoop对比

- Hadoop缺点：
  1. 表达能力有限，并不是所有任务都可以用MR完成
  2. 磁盘IO开销很大，要不断的读写磁盘，拖慢了速度
  3. 延迟高，map与reduce之间通过读写磁盘通信，任务之间衔接涉及IO开销
  4. 在前一个任务执行完成之前，其他任务就无法开始，难以胜任复杂、多阶段计算任务

- Spark相对Hadoop的优点
  1. Spark的计算模式也属于MapReduce，但不局限与Map和Reduce操作，还提供了多种数据集操作类型， 编程模型比Hadoop MapReduce更灵活，更为适合数据挖掘、机器学习的任务。
  2. Spark提供了内存计算，可将中间结果放到内存中，对于迭代运算效率更高
  3. Spark基于DAG的任务调度执行机制，相对于Hadoop，虽然有Tez框架也实现了DAG任务调度，但是仅是Tez框架，不是MapReduce框架本身，所以Spark要由于Hadoop MapReduce的迭代执行机制。

![Spark与Hadoop流程对比](/images/spark/spark1.png)

## Spark生态系统

- Spark设计：遵循 “一个软件栈满足不同应用场景” 的理念，逐渐形成了一套完整的生态系统

- Spark可以部署在资源管理器YARN之上，提供一站式的大数据解决方案
- Spark所提供的生态系统同时支持**批处理**、**交互式查询**和**流数据处理**
- Spark生态系统已经成为伯克利数据分析软件栈BDAS(Berkeley Data Analytics Stack)的重要组成部分
- 生态系统组成：
  1. Spark Core 提供内存计算
  2. Spark SQL 提供交互式查询分析
  3. Spark Streaming 提供流计算功能
  4. MLlib 提供机器学习算法库的组件
  5. GraphX 提供图计算

![Spark生态系统组件的应用场景](/images/spark/spark2.png)

